\chapter{Chapter Foo}

\section{ResNet}

In the ResNetSlide there is a figure with \say{skipping} arcs in the the layer right behind the layer with the filters.
The purpose of this architecture is to prevent the amount of information lost in the filters.

Fully Convolutional Nets

\section{Fully Connected Nets}

Slide 49: \say{Mathematically the same}.


\section{Neural network that return a image instead of a label}
\subsection{Encoder,- Decoder Architectures}

Consist of an encoder and a decoder.
\begin{itemize}
    \item The Encoder is a typical cnn.
    \item The decoder used for \say{upsampling}.

        \begin{itemize}
            \item Q\: How to generate information, if information is lost??
            \item A\: The \say{skipped} connections skipped above.
            \item Alternative of \say{Upsampling} is \say{Deconvolution}.
        \end{itemize}
\end{itemize}

\subsection{GANS: Generative Adversarial Nets}
    Consists of a generator and a discrimmitiver part.

\section{Attention}





